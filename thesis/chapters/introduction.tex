\gls{hpc} infrastructures are crucial for the advancement of scientific
research, as they offer unparalleled computational power that can be leveraged to perform the most
complex scientific experiments. This massive performance is required (among other use-cases) in
various scientific areas, such as weather forecasting~\cite{wrf}, computational fluid
dynamics~\cite{cfd}, bioinformatics~\cite{bioinformatics} or deep
learning~\cite{hpcdl}.

Over the last several decades, the performance of \gls{hpc} clusters
(\emph{supercomputers}) has been steadily increasing, effectively doubling every few years, in
line with Moore's Law and Dennard scaling~\cite{mooreslaw}. However, it also became more
difficult for \gls{hpc} users to tap into that performance increase. Thirty years ago,
it was possible to get essentially double the performance for free, just by using a new
(super)computer every two years, without having to modify existing programs. This phenomenon had
started to diminish by the end of the last century, as chip designers became limited by the memory
wall~\cite{memorywall} and especially the power wall~\cite{powerwall}.

To keep up with the expectations of exponential performance increases, \glspl{cpu} had
to become more complex. Processor manufacturers started implementing various buffers and caches,
multiple cores, simultaneous multithreading, out-of-order execution and a plethora of other
techniques that would allow the \gls{cpu} to run faster, without requiring massive
increases of power draw or memory bandwidth. The existence of multiple cores and sockets and the
need for ever-increasing memory sizes has also made the memory system more complex, with
\gls{numa} memories becoming commonplace in \gls{hpc}. To achieve even
more performance, \gls{hpc} clusters started massively adopting various accelerators,
like the Intel Xeon Phi~\cite{xeonphi} manycore coprocessor or general-purpose NVIDIA or
AMD \glspl{gpu}, which eventually became the backbone of the majority of current
supercomputers~\cite{top500gpu}. Some clusters have also adapted more unconventional
accelerators, like reconfigurable hardware, such as \glspl{fpga}, or
\gls{ai} accelerators, such as \glspl{tpu}. This trend gave rise to
heterogeneous clusters that offer various types of hardware, each designed for specific workloads.

These hardware improvements have managed to keep up with Moore's Law, but no longer without
requiring changes to the software. The increasing complexity and heterogeneity of
\gls{hpc} hardware has caused the ``\gls{hpc} software stack'' and the
corresponding programming models to become more complex, making it far from trivial to leverage the
available performance offered by supercomputers. Individual computers of \gls{hpc}
clusters (called \emph{computational nodes}) can consist of hundreds of \gls{cpu} cores
each, yet it is challenging to write programs that can scale to such high core counts. The
\gls{ram} of each node contains multiple levels of complex cache hierarchies, and it
has such a large capacity that it has to be split into multiple physical locations with varying
access latencies (\gls{numa}), which requires usage of specialized programming
techniques to achieve optimal performance. And the ever-present accelerators, for example
\glspl{gpu}, might require their users to adopt completely different programming models
and frameworks.

Historically, optimized \gls{hpc} software was primarily written using system or
scientifically focused programming languages (e.g.~\texttt{C}, \texttt{C++}
or \texttt{Fortran}) and specialized libraries for parallelizing and distributing
computation, such as \gls{openmp}~\cite{openmp}, CUDA~\cite{cuda} or
\gls{mpi}~\cite{mpistudy}. While these rather low-level technologies are able
to provide the best possible performance, it can be quite challenging and slow to develop (and
maintain) applications that use them. It is unreasonable to expect that most domain scientists that
develop software for \gls{hpc} clusters (who are often not primarily software
developers) will be able to use all these technologies efficiently without making the development
process slow and cumbersome. This task should be left to specialized performance engineers,
enabling the scientists to focus on the problem domain~\cite{dace}.

With the advent of more powerful hardware, \gls{hpc} systems are able to solve new
problems, which are more and more demanding, both in terms of the required computational power, but
also in terms of data management, network communication patterns and general software design and
architecture. Areas such as weather prediction, machine-learning model training or big data
analysis require executing thousands or even millions of simulations and experiments. These
experiments can be very complex, consisting of multiple dependent steps, such as data ingestion,
preprocessing, computation, postprocessing, visualization, etc. It is imperative for scientists to
have a quick way of prototyping these applications, because their requirements change rapidly, and
it would be infeasible to develop them using only very low-level technologies.

The growing complexity of \gls{hpc} hardware, software and use-cases has given rise to
the popularity of task-based programming models and paradigms. Task-oriented programming models
allow users to focus on their problem domain and quickly prototype, while still being able to
describe complicated computations with a large number of individual steps and to efficiently
utilize the available computational resources. With a task-based approach, a complex computation is
described using a set of atomic computational blocks (\emph{tasks}) that are composed
together in a \emph{task graph} which captures dependencies between the individual tasks. Task
graphs abstract away most of the complexity of network communication and parallelization, and they
are general enough to describe a large set of programs in a practical and simple way. At the same
time, they remain amenable to compiler-driven optimization and automatic parallelization, which
helps to bring the performance of programs described by a task graph close to manually parallelized
and distributed programs, at a fraction of the development cost for the application developer. They
are also relatively portable by default, as the task graph programming model typically does not
make many assumptions about the target platform; therefore, the same task graph can be executed on
various systems and clusters, if the tasks and a task graph execution tool can run on that cluster.

Combined with the fact that task-based tools often allow users to implement their workflows in very
high-level languages, such as Python or various \glspl{dsl}, it makes them an ideal tool
for rapid scientific prototyping. However, this does not mean that low-level high-performance
kernels are not being used anymore; a common approach is to describe the high-level communication
structure of the workflow using a task graph where the individual tasks execute the low-level
kernels, rather than implementing a monolithic application that performs all the network
communication explicitly.

Task graphs are already commonly being used and deployed on various distributed
systems~\cite{pegasus, workflows_at_scale, large_scale_modelling}, yet there are certain challenges that limit their usage ergonomics
and performance efficiency when deployed specifically on \gls{hpc} systems. These
challenges stem from various factors, such as the interaction of task graphs with
\gls{hpc} allocation managers, the heterogeneity and complexity of
\gls{hpc} cluster hardware, or simply from the potentially enormous computational
scale. When task graph authors encounter these problems, they might have to step out of the comfort
zone of this easy-to-use programming model, and implement parts of their applications using other,
more complicated approaches, to either meet their performance goals or to even make it possible to
execute their application on \gls{hpc} clusters at all. Removing or alleviating some
of those challenges could lower the barrier of entry, make task graph execution better suited for
various \gls{hpc} use-cases and turn it into an actual first-class citizen in the
world of supercomputing\@.

To achieve the goal of making it easier and more efficient to execute task graphs on heterogeneous
supercomputers, this thesis sets out the following objectives:

\begin{itemize}
	\item Identify and analyze existing challenges and bottlenecks of task graph execution on
	      \gls{hpc} clusters, particularly in the areas of efficient hardware utilization and
	      usage ergonomics, and examine how are existing tools able to deal with them.
	\item Describe a set of guidelines for overcoming these challenges that would enable effortless execution
	      of task graphs on modern heterogeneous clusters. These guidelines should serve as a template for
	      implementing \gls{hpc}-optimized task graph execution tools.
	\item Implement a task graph execution tool using these guidelines and evaluate it on
	      \gls{hpc} use-cases.
\end{itemize}

The thesis is structured as follows.~\Autoref{ch:distributed-computing} describes various approaches for
designing parallelized programs on distributed clusters, to provide context on how does task-based
programming relate to them. It also concretizes a specific subset of task-based programming
relevant for this thesis.~\Autoref{ch:taskgraphs} then defines key terms related to tasks and task
graphs in detail, to provide a shared vocabulary that will be used throughout this thesis. It is
followed by~\Autoref{ch:sota}, which discusses various ergonomic challenges and performance
bottlenecks faced by state-of-the-art distributed task runtimes when executing task graphs on
\gls{hpc} systems.

The following three chapters then discuss designs for overcoming these challenges.
Chapters~\ref{ch:estee} and~\ref{ch:rsds} focus solely on the efficiency
aspects.~\Autoref{ch:estee} evaluates the quality of various task scheduling algorithms, which
are important for achieving good performance when executing task workflows, and introduces
\estee{}, a task graph execution simulator that can be used to prototype new
scheduling algorithms.~\Autoref{ch:rsds} analyzes the runtime performance of
\dask{}, a state-of-the-art task runtime, and provides an alternative implementation
of its server that is able to outperform it in various \gls{hpc}
use-cases.~\Autoref{ch:hyperqueue} then focuses on improving both the ergonomic and performance
aspects of task execution using a meta-scheduling and resource management approach designed to
facilitate task graph execution on heterogeneous clusters. This approach has been implemented in
the \hyperqueue{} task runtime, which is also described and evaluated in this chapter in
detail. Finally,~\Autoref{ch:conclusion} summarizes the thesis and outlines future work.

%\begin{figure}
%	\centering
%	\begin{tikzpicture}[>=latex,line join=bevel,every text node part/.style={align=center}]
%		\tikzset {chapter/.style={rectangle, draw, minimum width=5cm, font=\footnotesize}}
%
%		\newcommand{\chname}[1]{\emph{\nameref{#1}}}
%		\newcommand{\chnum}[1]{\Autoref{#1}}
%
%		\node (distributed-computing) [chapter]
%		{\chname{ch:distributed-computing} \\\chnum{ch:distributed-computing}};
%
%		\node (taskgraphs) [chapter, below=of distributed-computing]
%		{\chname{ch:taskgraphs} \\\chnum{ch:taskgraphs}};
%
%		\node (estee) [chapter, below=of taskgraphs, xshift=3cm]
%		{\chname{ch:estee} \\\chnum{ch:estee}};
%
%		\node (challenges) [chapter, below=of taskgraphs,left=of estee, yshift=-1cm]
%		{\chname{ch:sota} \\\chnum{ch:sota}};
%
%		\node (rsds) [chapter, below=of estee]
%		{\chname{ch:rsds} \\\chnum{ch:rsds}};
%
%		\node (hq) [chapter, below=of rsds, xshift=-3cm]
%		{\chname{ch:hyperqueue} \\\chnum{ch:hyperqueue}};
%
%		\draw [->] (distributed-computing.south) -- (taskgraphs.north);
%		\draw [->] (taskgraphs.south) -- (challenges.north);
%		\draw [->] (challenges.south) -- (hq.north);
%		\draw [->] (taskgraphs.south) -- (estee.north);
%		\draw [->] (estee.south) -- (rsds.north);
%		\draw [->] (rsds.south) -- (hq.north);
%	\end{tikzpicture}
%	\caption{Diagram of the thesis chapters}
%	\label{fig:thesis-chapter-diagram}
%\end{figure}
