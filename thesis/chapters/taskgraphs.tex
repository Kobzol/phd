In order to discuss task-based programming, it is useful to provide a vocabulary of terms related
to it. This vocabulary necessarily has to be relatively general, in order to be applicable to a
wide range of systems; even though the previous chapter has specified a precise subset of
task-based programming models that will be examined and analyzed in this thesis, there is still a
large number of tools and systems that belong to this area of interest, each with their own
distinct concepts and semantic rules. Therefore, it is infeasible to provide a single unifying and
complete task theory that would encompass details of all these tools and programming models.

This chapter defines a set of concepts related to tasks, with a particular focus on properties that
are important for task graph execution in \gls{hpc} environments, which will be
further described in~\Autoref{ch:sota}. The definitions described in this chapter are
specifically adapted to the needs and terminology of this thesis, as is usual for other research
works. They form the lowest common denominator that can be applied to the specific task execution
tools and their programming models discussed throughout this thesis. The presented terms are
similar to definitions that can be found in existing works~\cite{task_scheduling,hagras2003static,wang2018list}. However, they
differ in several aspects. In particular, we do not assume that task execution times nor output
data sizes are known in advance, and we provide a very general definition of task resource
requirements, which can be used to model complex resource management of heterogeneous clusters.

\section{Task graphs}
\label{sec:task-graphs}
A computational workflow in the task-based programming model is represented with a
\gls{dag} that we will label as a \emph{task graph}. From a high-level
perspective, it describes which individual computational steps should be performed, what are the
constraints for where and in which order they should be computed and how should data be transferred
between the individual steps of the workflow.

There are many variations of task graphs, based on the computational properties that they are able
to describe. In the most basic form, task graph vertices represent computations to be performed,
and the arcs (edges) represent dependencies between the computations, which enforce an order in
which they should be executed. However, numerous other concepts can also be encoded in a task
graph. For example, in addition to dependencies, the arcs could represent abstract communication
channels, through which the outputs of one computation are transferred to become the inputs of
another computation that depends on it. As another example, there could be a special type of arc
which specifies that the outputs of a computation will be streamed to a follow-up computation,
instead of being transferred in bulk only after the previous computation has finished.

As was already noted, the exact semantics of vertices and arcs of task graphs depend heavily on the
specifics of tools that implement them, and thus it is not possible to provide a single definition
that would fit all variants used ``in the wild''. To provide a baseline definition, we will
formally define a task graph that can capture dependencies between tasks, the notion of
transferring data outputs between tasks, and where tasks can specify resources needed for their
execution.

\newcommand{\alltaskpairs}{\forall t_1\in{}T, \forall t_2\in{}T}

A task graph is a tuple $(T, O, E, \setresourcekinds, \fntaskres)$, where:
\begin{itemize}[itemsep=0pt]
	\item $T$ is a set of \emph{tasks}.
	\item $O$ is a set of \emph{data objects}.
	\item $E \subseteq ((T\times{}O) \cup (O\times{}T))$ is a set of arcs.
	\item $\setresourcekinds$ is a set of \emph{resource kinds}. Each resource kind describes some resource
	      (e.g. \gls{cpu} cores or \glspl{gpu})
	      that is required to execute a specific task.
	\item[\makedef{def:task_resreq}] $\fntaskres$ is a function that defines the
		\emph{resource requirement} of a task for a specific resource kind: \\
		\resourcerequirement{\fntaskres}{N} \\
		A resource requirement specifies what amount of the given resource kind is required to be present
		at a computational provider so that the task can be executed. If $\fntaskres(t, r) = 0$, then task
		$t$ does not require resource $r$ for its execution.
\end{itemize}

$(T \cup O, E)$ forms a finite directed acyclic graph (a graph without cycles). The graph is
structured in a way so that for every data object, there is exactly one task that produces it: \\
$\forall o \in O: |E \cap (T \times \{o\})| = 1$

\vspace{2mm}Below we will define several terms that will be useful for describing task
graphs and their properties:
\begin{itemize}
	\item If there is an arc from a task to a data object ($(t,o) \in (T\times{}O)$), then we call
	      $t$ the \emph{producer} of $o$ and
	      $o$ the \emph{output} of $t$.
	\item If there is an arc from a data object to a task ($(o,t) \in (O\times{}T)$), then we call
	      $t$ the \emph{consumer} of $o$ and
	      $o$ the \emph{input} of $t$.

	\item Let us introduce a binary relation $D_r$: \\ $D_r: T \times T = \{(t_1, t_2) \mid (t_1, t_2)\in{}(T\times{}T)\land t_1 \neq t_2 \land
		      \exists{}o\in{}O\colon (t_1, o)\in{}E
		      \land (o, t_2)\in{}E\}$ \\ When
	      $(t_1, t_2) \in D_r$, we say that $t_2$ \emph{directly depends} on
	      $t_1$. We can also state that $t_2$ consumes the output produced
	      by $t_1$.

	\item Let us introduce a binary relation $D$: \\ $D: T \times T = \{(t_1, t_2) \mid \exists{}n (t_1, t_2, \ldots, t_n)\colon \forall i
		      \in \{1,2,\ldots,n - 1\}\colon (t_i, t_{i+1}) \in{} D_r\}$ \\ When
	      $(t_1, t_2) \in D$, we say that $t_2$ \emph{depends} on
	      $t_1$ and that $t_1$ is a \emph{dependency} of
	      $t_2$.

	\item We label tasks without any dependencies \emph{source tasks}: \\ $S = \{ t \mid t\in{}T \land
		      \forall{}t_d\in{}T\colon (t_d, t)\notin D\}$ \\ It is
	      a simple observation that unless the task graph is empty ($(T\cup{}O) = \emptyset$), there is always
	      at least one source task in the graph, because the graph is acyclic.
\end{itemize}

% \footnote{This representation will be used in all following task graph diagrams.}

An example of a simple task graph is shown in~\Autoref{fig:task-graph-example}. Tasks are represented as
circles, data objects as (rounded) rectangles and arcs as arrows. The task $t_0$
generates two data objects, which are then used as inputs for four additional tasks. The outputs of
these four tasks are then aggregated by a final task $t_5$. This can correspond
e.g.\ to a workflow where $t_0$ generates some data, $t_{1-4}$
performs a calculation on that data and $t_5$ then performs a final
post-processing step and stores the results to disk.

\begin{figure}[h]
	\centering
	\resizebox{!}{35mm}{
	\begin{tikzpicture}
			\tikzset{%
				data/.style={rectangle, draw, rounded corners, minimum size=8mm},
			}
            \graph[
                grow right sep=11mm,
            ] {
                "$t_1$"[task] -> {
                    "$o_{1a}$"[data] -> {
                        "$t_2$"[task] -> "$o_{2}$"[data],
                        "$t_3$"[task] -> "$o_{3}$"[data],
                        "$t_4$"[task] -> "$o_{4}$"[data]
                    },
                    "$o_{1b}$"[data] -> {
                        "$t_5$"[task] -> "$o_{5}$"[data]
                    }
                } -> "$t_6$"[task]
            };
        \end{tikzpicture}
	}
	\caption{Simple task graph with six tasks and six data objects}
	\label{fig:task-graph-example}
\end{figure}

Note that the presented definition of a task graph does not describe its semantics -- how will the
graph be created and executed and what will be the interactions between tasks and data objects.
This depends on the specific tool or framework that will execute the task graph. As an example, the
dependence of task $t_2$ on task $t_1$ could define the following
invariant: $t_2$ cannot start to execute until $t_1$ has finished
executing and the data objects produced by $t_1$ have been transferred to the
computational node that will execute $t_2$. A formal definition of a basic set of
execution and scheduling semantics will be provided in~\Autoref{sec:task-scheduling}.

A \emph{task} is a serializable description of a computation that can be executed
repeatedly. The serializability property is crucial, as it allow us to treat computation as data.
That is a powerful concept, because it allows tasks to be sent between different nodes in a cluster
or stored to disk and to be transparently recomputed an arbitrary number of times. Enabling the
recomputation of tasks is useful for achieving fault tolerance, as tasks might need to be
recomputed later if some failure occurs during their execution.

In practice, a single task will typically represent either the invocation a function (an executable
block of code) or the execution of a whole program. Multiple tasks in a task graph can refer to the
same function or program, since each such task can have different inputs. In fact, this is a common
case, as task graphs are often used to parametrize a small set of functions or programs with many
different input parameters.

Even though the inputs and outputs of tasks were defined as sets in the formal definition, in
practice they are usually stored using either ordered sequences or a mapping that associates a name
with each input or output, because it is important to maintain a specific ordering of both inputs
and outputs. For functions, the inputs are passed as arguments, and the output is derived from its
return value (which can potentially form a sequence of values). Therefore, we have to be able to
associate each task input to a specific argument index. The same holds for tasks that execute
programs. In this case, inputs can be mapped to command-line arguments and the content of the
\texttt{standard input stream}, and the output can be e.g.\ the content of the \texttt{standard output stream}
generated by the executed program.

Each task can define its \emph{resource requirements}, a set of constraints for the worker(s) that are
able to execute that task. As an example, a task that performs training of a machine-learning model
might require a \gls{gpu} to be present on the worker where the task will be executed.
Other resources might include e.g.\ a specific number of \gls{cpu} cores or a minimum
amount of \gls{ram} or necessary to execute a given task.

A \emph{data object} represents a dynamically computed result of a task; it is not known at the
time of the task graph creation. Typically, it is a serialized blob of data that is eventually
transferred from the node where its producer was computed to the node where its consumer should be
executed. If a task programming model does not encode direct data transfers between tasks, then
data objects simply serve as ``empty'' markers of dependencies, and they do not hold any actual
data. In that case, we could even remove them from the task graph completely, and represent task
dependencies directly with arcs between tasks.

It is important to note that not all data used by tasks has to be encoded as a data object in the
task graph. As an example, tasks that represent function invocations are usually created by the
execution of some program (e.g.\ a Python script). A task graph defined in this way is usually
constructed with a specific set of input data for its \emph{source tasks}. This data can be
embedded directly within the definition of the function itself; in that case it is not represented
as an explicit data object. In other words, a task might represent a serializable description of a
computation along with its input data. That is why in the presented formal definition,
\emph{source tasks} do not have any explicit \emph{inputs}, as it is expected that
input data is embedded directly within them.

Additionally, when a task is executed, it can also read and modify the state of the environment in
which it is being executed, in a way that is observable by other tasks. For example, a function can
read or modify the value of a global variable, while a program can read an environment variable or
create a file on a disk, without it being specified as a task output. Such actions, which we will
label as \emph{side effects}, are also typically not encoded within the task graph. Tasks should
ideally contain as few side effects as possible, because they can make task execution
non-deterministic, causing them to produce different outputs when executed multiple times, which is
typically undesirable.

In general, the most important goal of the task graph is to encode high-level structure of the
computation (such as dependencies between tasks), which enables a task execution tool to
automatically execute the task graph in a parallel fashion. However, many details about the
computation itself are specified outside the task graph itself.

\section{Task execution}
Task graphs merely describe some computation; therefore, they have to be executed in order to
actually produce some outputs and results. This is the responsibility of a \emph{task runtime},
a tool that analyzes task graphs and executes them in some \emph{computational environment}, e.g.\ a personal
computer or a distributed cluster. Such an environment contains a set of computational providers
that are able to execute tasks. We will label these providers as \emph{workers}. A worker
can execute a task by invoking the computation assigned to it (typically by calling a function or
executing a program), and passing it the inputs of the task. Usually a task can only be executed
once all of its inputs are ready, which means that the dependencies of the task have been computed,
and their outputs have been transferred to the computational node of the worker. However, this
depends on the semantics of each task runtime.

We can formally define a \emph{computational environment} as a tuple $(W, \setresourcekinds, \fnworkerres)$, where:
\begin{itemize}[itemsep=0pt]
	\item $W$ is a set of workers.
	\item $\setresourcekinds$ is a set of \emph{resource kinds}. Each resource kind describes some
	      resource (e.g. \gls{cpu} cores or \glspl{gpu}) that can be provided a
	      worker.
	\item[\makedef{def:worker_resources}] $\fnworkerres$ is a function which defines how many resources are
		provided by a worker for a specific resource kind: \\ $\fnworkerres\colon W \times \setresourcekinds \rightarrow
			\mathbb{N}_{\geq{}0}$
\end{itemize}

There are many existing task runtimes with varying architectures, features and trade-offs, which
affect factors like performance, fault tolerance or expressivity of the supported variant of the
task-based programming model. Several task runtimes will be discussed throughout this thesis. In
the rest of this section, we will consider a case typical for \gls{hpc} environments;
a distributed task runtime with a central manager that communicates with a set of workers running
on remote nodes that communicate together via a network.

In general, a task runtime oversees all aspects of task graph execution. Its two main
responsibilities can be divided into managing communication with the workers, and handling the
scheduling and execution of tasks.

Worker management involves handling the lifetime of workers (connection and disconnection from the
cluster), facilitating data transfers between them or providing resiliency in case of worker
failures. A single worker is typically a program running on a computational node, which is
connected to the runtime manager. It receives commands from it, executes tasks and sends
information about task execution statuses back to the manager. Each worker typically manages some
hardware resources that are available for tasks during their execution. Hardware resources can be
assigned to workers in various ways. There can be a single worker per the whole computational node,
or there could be multiple workers per node, each managing a subset of the available resources
(e.g.\ a single worker per \gls{cpu} core).

The second main aspect that has to be handled by the runtime is the management of tasks. It has to
keep track of which tasks have already been computed, which tasks are currently being executed on
some worker(s) or which tasks are ready to be executed next, because their dependencies have
already been computed. Two important responsibilities in this area are fault tolerance and
scheduling.

In the context of task graph execution, we will define \emph{fault tolerance} as the ability to
gracefully handle task execution failures, and provide ways of retrying failed computations. When
the execution of a task fails with some error condition (e.g.\ because a worker executing the task
crashes), a fault-tolerant task runtime will be able to transparently restart it by launching a new
execution of that task. We will use the term \emph{task instance} for a specific execution of a
task. Runtimes might impose some limits on retrying failed tasks, e.g.\ by attempting to execute up
to a fixed number of task instances for each task before giving up, to avoid endless failure loops.

The fact that it is even possible to execute a task multiple times is one of the main advantages of
the task-based programming model, where tasks declaratively describe a self-contained computation
that can be re-executed arbitrarily many times. This crucial property of tasks makes fault-tolerant
execution of task graphs easier to achieve than in other programming models, where individual
computations are not self-contained and serializable.

\section{Task scheduling}
\label{sec:task-scheduling}
One of the most important responsibilities of a task runtime is \emph{task scheduling}. It is the
act of deciding in which order and on which specific worker(s) should each task execute, in a way
that optimizes some key metric. We will use the term \emph{scheduler} for a component of the
task runtime that is responsible for assigning tasks to workers by creating
\emph{schedules}. A schedule is a mapping that assigns tasks to specific workers that should
execute them, and also assigns an order in which the tasks should be executed. It can be
\emph{static}, in which case it is produced just once before the task graph begins
executing, or \emph{dynamic}, where the scheduler generates the assignments on-the-fly,
based on the current utilization of workers and the observed durations of tasks that have already
been executed. Some schedulers also retroactively modify already produced schedules in reaction to
dynamic situations that occur during task graph execution (e.g.\ if a new worker connects to the
cluster, or if some worker is starving).

We will split the formal definition of a \emph{schedule} into two parts, because the
schedule decides both the worker that executes a given task, and also the ordering in which tasks
are executed. As mentioned earlier, a schedule can be produced either before the task graph is
executed or during its execution. The following definitions are general and work for both
approaches.

We can define a \emph{schedule} as a pair $(\scheduleworker, \scheduleorder)$ applied to a task graph
$(T, O, E, \setresourcekinds, \fntaskres)$ and a computational environment $(W, \setresourcekinds, \fnworkerres)$ as follows:

\begin{itemize}[itemsep=0pt]
	\item A worker schedule $\scheduleworker$ is a function that assigns each task to a specific worker:
	      \\ $\scheduleworker\colon T \rightarrow W$
	\item An ordering schedule $\scheduleorder$ is a function that assigns a unique number to each
	      task, to define an (approximate) ordering in which tasks should be executed: \\
	      $\scheduleorder\colon T \rightarrow \mathbb{O}, \mathbb{O} =
		      \{1,\ldots,|T|\},
		      \alltaskpairs\colon \scheduleorder(t_1) = \scheduleorder(t_2) \Rightarrow t_1 = t_2$
\end{itemize}

This definition supports only single-node tasks, i.e.\ tasks that are always executed on exactly a
single node. It could be generalized for other use-cases that have a more complex programming
model. For example, we could add support for multi-node tasks by generalizing the worker schedule
to be a mapping of tasks to a non-empty set of workers: \\ $\scheduleworker\colon T \rightarrow \powerset{W}, \forall
	t\in{}T\colon |\scheduleworker(t)| > 0$

Usually, we will want the produced schedules to have additional desirable properties, such as
respecting the dependencies and resource requirements of tasks in the task graph. Even though the
specifics of these properties differ in each task-based programming model, we can define a set of
baseline properties that are desirable in almost all situations. In order to do that, we will need
to consider a specific execution of a task graph that used a given schedule; we can then evaluate
whether that schedule satisfied these properties in the context of this execution.

Assume that we want to evaluate a specific schedule ($\scheduleworker$,
$\scheduleorder$) that was used to execute a task graph $(T, O, E, \setresourcekinds, \fntaskres)$ in a
computational environment $(W, \setresourcekinds, \fnworkerres)$ in some execution $X$. For
simplicity, we assume exactly one task instance executed for each task. In other words, tasks in
this execution did not fail and each task was fully executed. First, let us define several
auxiliary functions:

\newcommand{\timedomain}{\mathbb{R}_{\geq{}0}}

\begin{itemize}
	\item Let us have a function $\fntaskstart$ that returns the point in time at which a specific
	      task started its execution in $X$: $\fntaskstart\colon T \rightarrow \timedomain$
	\item Let us have a function $\fntaskfinish$ that returns the point in time at which a specific
	      task finished its execution in $X$: $\fntaskfinish\colon T \rightarrow \timedomain$
	\item Let us have a function $\fnworkertaskassigned$ that returns a set of tasks that were currently being
	      executed on a specific worker at a given point in time in $X$:
	      $\fnworkertaskassigned\colon W \times \timedomain \rightarrow \powerset{T}$
\end{itemize}

We will say that a schedule is \emph{valid} in $X$ when all the
following properties hold:

\begin{itemize}
	\item The ordering of task execution defined by $\scheduleorder$ has to be upheld: \\
	      $\alltaskpairs\colon \scheduleorder(t_1) < \scheduleorder(t_2) \Rightarrow \fntaskstart(t_1) \leq
		      \fntaskstart(t_2)$
	\item If a task $t_2$ depends on a task $t_1$, it cannot begin to
	      execute until $t_1$ has finished executing: \\ $\alltaskpairs\colon D(t_1, t_2) \Rightarrow \fntaskfinish(t_1) \leq \fntaskstart(t_2)$
	\item[\makedef{def:worker_resource_constraint}] Resource requirements of all tasks must be fulfilled and resources provided by individual workers
		must not be oversubscribed at any point in time: \\ $\forall tp\in\timedomain, \forall w\in{}W, \forall
			r\in{}\setresourcekinds\colon
			\mathlarger{\sum}_{t\in{}\fnworkertaskassigned(w, tp)} \fntaskres(t, r) \leq
			\fnworkerres(w, r)$ \\ We will label this
		property as \emph{worker resource constraint}.
\end{itemize}

% TODO: generalize ``validness'' to executions? Use it more?
Since these properties form the bare minimum that a reasonable schedule should support, we will
assume that all further schedules discussed in this thesis are \emph{valid}.

We can further evaluate the quality of a schedule on various metrics. There are many such metrics
that a scheduler can optimize for, such as the latency to execute specific critical tasks, but the
most commonly used metric is \emph{makespan} -- the duration between the start of the
execution of the first task to the completion of all tasks within the task graph. We can formally
define the makespan $M$ of a specific task graph execution as follows: \\
$M = \max\limits_{t \in T}(\fntaskfinish(t)) - \min\limits_{t \in T}(\fntaskstart(t))$

\begin{figure}[h]
	\centering
	\resizebox{!}{70mm}{
	\begin{tikzpicture}
			\tikzmath{
				\tzerowidth = 15mm;
				\tonewidth = 20mm;
				\ttwowidth = 25mm;
				\tthreewidth = 35mm;
				\ozerowidth = 15mm;
				\oonewidth = 30mm;
			}
			\tikzset {
				taskstyle/.style={fill={rgb,255:red,21; green,66; blue,100}, text=white, draw=none},
				objstyle/.style={fill=black!60!green, text=white, draw=none},
			}

			% T1
			\node[task, taskstyle, minimum size=7.5mm] (t1) at (0, 0.5) {$t_1$};
			\node[data, objstyle, minimum size=5mm] (d1a) at (-1, -1) {$d_1$};
			\node[data, objstyle, minimum size=10mm] (d1b) at (1, -1) {$d_2$};
			\draw [arrow] (t1) edge (d1a.north) (t1) edge (d1b.north);

			% T2 and T3
			\node[task, taskstyle, minimum size=10mm] (t2) at (-2, -2.5) {$t_2$};
			\node[task, taskstyle, minimum size=12.5mm] (t3) at (0, -2.5) {$t_3$};
			\draw [arrow] (d1a) edge (t2.north) (d1a) edge (t3.north);

			% T4
			\node[task, taskstyle, minimum size=17.5mm] (t4) at (2, -2.5) {$t_4$};
			\draw [arrow] (d1b.south) edge (t4.north);

			% Move to the right to draw the timelines
			\tikzset{shift={(4,2)}}

			\node[anchor=west,align=left] at (0, 0) {
				$\scheduleworker^1(t_1) = w_1, \scheduleworker^1(t_2) = w_1, \scheduleworker^1(t_3) = w_2, \scheduleworker^1(t_4) = w_3$ \\
				$\scheduleorder^1(t_1) = 1, \scheduleorder^1(t_2) = 2, \scheduleorder^1(t_3) = 3, \scheduleorder^1(t_4) = 4$
			};

			\tikzset{shift={(0,-1)}}
			\node (tim1A) at (0, 0) {$w_1$};
			\draw[arrow] (tim1A.east) -- ++(9, 0);
			\node[below = 0.5 of tim1A.south] (tim1B) {$w_2$};
			\draw[arrow] (tim1B.east) -- ++(9, 0);
			\node[below = 0.5 of tim1B.south] (tim1C) {$w_3$};
			\draw[arrow] (tim1C.east) -- ++(9, 0);

			% Timeline 1, row 1
			\node[taskstyle, minimum width=\tzerowidth, right = 0.2 of tim1A.east] (tim1t0) {$t_1$};
			\node[taskstyle, minimum width=\tonewidth, right = 0.1 of tim1t0.east] (tim1t1) {$t_2$};

			% Timeline 1, row 2
			\node[objstyle, minimum width=\ozerowidth, below = 1 of tim1t1.west, anchor=west]
			(tim1o0) {$d_1$ ($w_1$)};
			\node[taskstyle, minimum width=\ttwowidth, right = 0.1 of tim1o0.east] (tim1t2) {$t_3$};

			% Timeline 1, row 3
			\node[objstyle, minimum width=\oonewidth, below = 1 of tim1o0.west, anchor=west]
			(tim1o1) {$d_2$ ($w_1$)};
			\node[taskstyle, minimum width=\tthreewidth, right = 0.1 of tim1o1.east]
			(tim1t3) {$t_4$};

			\draw[dashed, draw=red] (tim1t0.west) -- ++(0, -2.75) --
			([shift=({0,-0.75})]tim1t3.east) -- (tim1t3.east);

			\node[text=red] at (4.5, -3) {Makespan};

			% Move below to draw the timelines
			\tikzset{shift={(0,-4)}}

			\node[anchor=west,align=left] at (0, 0) {
				$\scheduleworker^2(t_1) = w_1, \scheduleworker^2(t_2) = w_2, \scheduleworker^2(t_3) = w_3, \scheduleworker^2(t_4) = w_1$ \\
				$\scheduleorder^2(t_1) = 1, \scheduleorder^2(t_2) = 3, \scheduleorder^2(t_3) = 4, \scheduleorder^2(t_4) = 2$
			};

			\tikzset{shift={(0,-1)}}
			\node (tim2A) at (0, 0) {$w_1$};
			\draw[arrow] (tim2A.east) -- ++(9, 0);
			\node[below = 0.5 of tim2A.south] (tim2B) {$w_2$};
			\draw[arrow] (tim2B.east) -- ++(9, 0);
			\node[below = 0.5 of tim2B.south] (tim2C) {$w_3$};
			\draw[arrow] (tim2C.east) -- ++(9, 0);

			% Timeline 2, row 1
			\node[taskstyle, minimum width=\tzerowidth, right = 0.2 of tim2A.east] (tim2t0) {$t_1$};
			\node[taskstyle, minimum width=\tthreewidth, right = 0.1 of tim2t0.east] (tim2t1)
			{$t_4$};

			% Timeline 2, row 2
			\node[objstyle, minimum width=\ozerowidth, below = 1 of tim2t1.west, anchor=west]
			(tim2o0) {$d_1$ ($w_1$)};
			\node[taskstyle, minimum width=\ttwowidth, right = 0.1 of tim2o0.east] (tim2t2) {$t_3$};

			% Timeline 2, row 3
			\node[objstyle, minimum width=\ozerowidth, below = 1 of tim2o0.west, anchor=west]
			(tim2o1) {$d_1$ ($w_1$)};
			\node[taskstyle, minimum width=\tonewidth, right = 0.1 of tim2o1.east] (tim2t3) {$t_2$};

			\draw[dashed, draw=red] (tim2t0.west) -- ++(0, -2.75) --
			([shift=({0,-1.75})]tim2t2.east) -- (tim2t2.east);
		\end{tikzpicture}
	}
	\caption{Simple task graph and two different schedules}
	\label{fig:scheduling-example}
\end{figure}

\vspace{2mm}Task scheduling is so crucial because it has a profound effect on the
efficiency of the whole workflow execution. We can observe that in~\Autoref{fig:scheduling-example}, which
shows a schedule for a simple task graph, and demonstrates how a trivial change in the schedule can
severely affect the resulting makespan. The figure contains a task graph with four tasks and two
data objects. The size of the circles is proportional to the execution duration of the tasks and
the size of the rounded rectangles is proportional to the size of the data objects.

Let us assume that we want to schedule this task graph in a computational environment with three
workers $(w_1, w_2, w_3)$. Two different schedules for this situation are shown in the figure.
Schedule $S^1$ assigns tasks $t_1$ and $t_2$ to
worker $w_1$, task $t_3$ to worker $w_2$ and
task $t_4$ to worker $w_3$, while schedule $S^2$
assigns tasks $t_1$ and $t_4$ to worker $w_1$,
task $t_3$ to worker $w_2$ and task $t_2$ to
worker $w_3$. The timelines shows the execution of tasks (blue rectangles) and
the network transfers of data objects between workers (green rectangles) for each individual
worker. It is clear that with $S^2$, the task graph will be computed faster than
with $S^1$, even though the only difference between the two schedules is that the
tasks $t_2$ and $t_4$ were swapped between workers
$w_1$ and $w_3$. Note that the timeline assumes that a worker
can overlap the computation of a task with the transfer a data object to another worker over the
network, which is commonly supported by existing task runtimes.

Optimal scheduling of tasks to workers is an NP-hard~\cite{Ullman1975} problem even for the
most basic scenarios, when the exact execution duration of each task is known, and even if we do
not consider the duration of transferring data between workers over a network. Task runtimes thus
resort to various heuristics tailored to their users' needs. Some classic task scheduling
heuristics and their comparisons can be found in~\cite{estee,hlfet1974,kwok1998benchmarking,hagras2003static,wang2018list}. \Autoref{ch:estee}
provides a comprehensive survey of various task scheduling algorithms.

%Scheduling heuristics have to take many factors into consideration when deciding on which worker
%should a task be executed:
%
%\begin{description}[wide=0pt]
%	\item[Resource requirements] The scheduler should respect all resource requirements specified by tasks. The runtime thus has to
%		observe the dynamically changing available resources of each worker and schedule tasks accordingly,
%		to uphold their requirements. This can be challenging especially in the presence of complex
%		resource requirements.
%	\item[Data transfer cost] If the runtime operates within a distributed cluster, one of the most important scheduling aspects
%		that it needs to consider is the transfer cost of data between workers over the network. All
%		benefits gained by computing a task on another worker to achieve more parallelization might be lost
%		if it takes too much time to send the data (task outputs) to that worker.
%
%		The scheduler thus has to carefully balance the communication-to-computation ratio, based on the
%		available network bandwidth, sizes of outputs produced by tasks and the current utilization of
%		workers.
%	\item[Scheduling overhead] The overhead of generating the schedule itself also cannot be underestimated. As was already
%		stated, computing an optimal solution quickly is infeasible, but even heuristical approaches can
%		have wildly different performance characteristics. Producing a lower quality schedule sooner,
%		rather than a higher quality schedule later, can be sometimes beneficial.
%	\item[Memory consumption] It is desirable to execute as many tasks in parallel on a given worker (with respect to its
%		available parallelism), to speed up the completion of the whole workflow. However, the scheduler
%		should also balance the number of concurrently executing tasks according to the total amount of
%		memory that they consume. In general, it is difficult to predict for how long will a task execute,
%		and how much (peak) memory will it consume. When a task executes longer than expected, the workflow
%		will still be computed, it will just take more time. But when a task uses more memory than
%		expected, or the scheduler puts too many tasks on a worker at the same time, then the worker might
%		run out of memory and crash. If this happens repeatedly, it can stall or completely stop the
%		execution of the workflow. For memory-intensive workflows, the runtime should assign fewer tasks at
%		the same time to a single worker, or reduce overall memory consumption in some other way, e.g.\ by
%		keeping less cached data objects in the worker's memory.
%\end{description}

\section*{Summary}
This chapter has provided a basic definition of the most important terms related to task-based
programming models that will be used throughout this chapter. It has introduced the notion of task
graphs, tasks, data objects, resource requirements, workers, task runtimes and task scheduling.

The following chapter will focus on describing what challenges are faced by users and task runtimes
when they execute task graphs on \gls{hpc} clusters.
