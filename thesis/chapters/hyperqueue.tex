Both of the tools and their corresponding experiments that were presented in this thesis so far
(\estee{} and \rsds{}), were focused solely on the performance of
executing task graphs. While high performance is of course crucial for \gls{hpc}
use-cases, there are also other important aspects. One of these is the \emph{ergonomics} of
executing task graphs. This topic sometimes tends to be neglected in \gls{hpc}
applications and tools, which can be notoriously difficult to deploy or execute. Executing task
graphs on \gls{hpc} clusters does not \emph{need} to be difficult though, if
we use specialized approaches, rather than off-the-shelf tools that are not prepared to deal with
the complexities of \gls{hpc} systems. Furthermore, ergonomics and performance do not
have to contradict each other -- as we will see in this chapter, approaches that increase
ergonomics can also help with improving performance and hardware utilization.

% TODO: contributions?
%\hyperqueue{} contains the following contributions:
%\begin{enumerate}
%    \item
%\end{enumerate}

%Some descriptions of \hyperqueue{} and related concepts in this chapter were adapted from our
%publication~\cite{TODO}.

This chapter presents \hyperqueue{}, an \gls{hpc}-tailored task runtime that
was designed to enable transparent, ergonomic and efficient execution of task graphs on
\gls{hpc} systems. \hyperqueue{} is a spiritual successor of
\rsds{}, and builds upon its server and task scheduler implementation, however it
does not use the \dask{} interface. It is also the culmination of the research and
work presented in this thesis, which was made possible thanks to the experience gained from
\estee{} and \rsds{}, and also from working with task graphs in an
\gls{hpc} setting over the course of several years.

\workshare{I have collaborated on this work with Ada BÃ¶hm, we have both contributed to it equally. I am the sole author of the design and implementation of
specific components of \hyperqueue{},
these will be marked as such in the rest of this chapter. While me and Ada are the primary
contributors to \hyperqueue{}, it should be noted that multiple other people have contributed to it, as its development is a team effort. Source code contribution statistics for \hyperqueue{}
can be found on GitHub\footnoteurl{https://github.com/it4innovations/hyperqueue/graphs/contributors}.}

%TODO: architecture

% TODO: rename to "Interaction with allocation manager"
\section{Design of \hyperqueue{}}
\label{sec:hq-design}
This section describes the high-level design of \hyperqueue{}, its most important features
and also how it tackles the challenges mentioned in \Autoref{ch:challenges}. First, we will take a
look at how \hyperqueue{} interacts with \gls{hpc} allocation managers,
because that is the most important aspect of its design. Note that for simplicity, Slurm will be
used as an example of an allocation manager throughout this whole chapter, but it could be replaced
by PBS or any other commonly used allocation manager without the loss of generality.

As you may recall from~\Autoref{sec:allocation-manager}, perhaps the most pronounced ergonomic challenge of
executing a task graph on an \gls{hpc} cluster is the presence of an allocation
manager. Due to the limits imposed by it, it might be necessary to partition task graphs into
multiple subgraphs in order to be fit them within an allocation, which can be challenging.
Furthermore, it can result in non-optimal usage of hardware resources, because tasks from
(sub)graphs submitted in separate allocations will only be load balanced within their own
allocation, and not across different allocations.

The following process describes how computations are typically executed on \gls{hpc}
clusters in the presence of an allocation manager:

\begin{enumerate}
	\item The user sends a computational request (allocation) to the manager. It specifies how many nodes
	      should be allocated, and what is the maximum duration of the computation (usually labeled as
	      \emph{wall-time}), after which the computation will be forcibly stopped.
	\item The allocation manager enqueues the request, and schedules it to be executed at some time in the
	      future.
	\item Once the allocation is ready, the manager provisions the requested amount of hardware resources
	      (typically a number of whole computational nodes) and either executes a script on one of the
	      allocated nodes, or provides the user with an interactive terminal session connected to one of the
	      allocated nodes.
\end{enumerate}

The primary issue of this mechanism is that it strictly ties together two separate aspects --
\emph{what} does the user want to compute (the script that will be computed in the
allocation) and \emph{where} should the computation take place (specific hardware
resources and computational nodes). As was described in the process above, both of these things
have to be specified together in an allocation.

This approach works well when the granularity of the computation very closely matches the
granularity of the requested hardware resources, and when the computation can make use of all the
available hardware resources for the whole duration of the allocation. For example, distributed
applications implemented using \gls{mpi} typically expect that they will be executed
on a fixed amount of nodes, and that they will (ideally) use all their resources for the whole
computation. They can also run for a potentially long time, e.g.\ hours, days or even more. Due to
these properties, these applications fit the allocation model quite well.

However, the situation is quite different for applications implemented with a task-based
programming model. Task graphs do not assume a fixed amount of hardware resources. Even though
individual tasks can specify their resource requirements, the specific set of resources on which
the tasks execute can change during the computation of the task graph. Task graphs are thus
designed to scale both up and down, in terms of hardware resource usage. However, this is not
easily achieved when we compute a task graph inside a single allocation, because new resources
cannot be dynamically added or removed from an allocation.

The absence of scaling down can also lead to a waste of resources. For example, assume that we will
execute a task graph inside an allocation that contains two nodes. The tasks will be load-balanced
amongst these two nodes, but towards the end of the computation, there might be tasks that will
take a long time to finish. This might lead to a situation where only one of the nodes will be
computing the long tail of the remaining tasks, while the second node will be idle. Due to the fact
that the allocation cannot release the second node while the computation is still ongoing, the user
will unnecessarily pay the cost of both nodes until the task graph finishes computing, even though
the second node might be idle.

- an even bigger problem if you combine resources, e.g.\ CPU + GPU tasks





\hyperqueue{} takes a holistic approach to facilitating task graph scheduling on
\gls{hpc} clusters.



The key idea of \hyperqueue{} is to disentangle the definition of the computation (tasks)
and the hardware resources (computational nodes) where the computation will take place.

- moves the responsibility of performing the task to allocation mapping from the user to
\hyperqueue{},
which improves ergonomics.


Features: - deployment - load balancing - resources - auto allocation - local experimentation -
efficiency

%\hyperqueue{} is an \gls{hpc}-tailored task runtime designed for executing task graphs in \gls{hpc}
%environments. Its two primary objectives are to be as performant as possible and to be easy to use
%and deploy. It is developed in the Rust programming language and available as an open-source
%software\footnoteurl{https://github.com/it4innovations/hyperqueue}.
%
%The key idea of \hyperqueue{} is to disentangle the submission of computation and the provision of
%computational resources. With traditional \gls{hpc} job managers, the computation description is
%closely tied to the request of computational resources, which leads to problems mentioned in
%\Autoref{sec:challenges}, such as less efficient load balancing or the need to manually
%aggregate tasks into jobs. \hyperqueue{} separates these two actions; users submit task graphs
%independently of providing computational resources (workers) and let the task runtime take care of
%matching them together, based on requested resource requirements and other constraints.
%
%One of the driving use-cases for \hyperqueue{} is efficient node usage and load balancing. The
%latest \gls{hpc} clusters contain a large number (hundreds) of cores, yet it is quite challenging to
%design a single program that can scale effectively with so many threads. Thus, in order to fully
%utilize the whole computational node, multiple tasks that each leverage a smaller number of
%threads have to be executed on the same node at once. \hyperqueue{} is able to effectively schedule
%tasks to utilize all available computational nodes, and thanks to its design, it is able to do this
%not just within a single \gls{hpc} job, but across many jobs at once.
%
%\hyperqueue{} is being used by users of various \gls{hpc} centres, and it is also a key
%component of the Horizon 2020 European Union projects
%LIGATE\footnoteurl{https://www.ligateproject.eu},
%EVEREST\footnoteurl{https://everest-h2020.eu} and
%ACROSS\footnoteurl{https://across-h2020.eu}. It is also envisioned as one of the primary ways of
%executing computations on the LUMI supercomputer~\cite{lumi_it4innovations_2022}.
%

Modern \gls{hpc} clusters contain a large number of heterogeneous resources that
provide vast amounts of computational power. It is challenging to design monolithic programs that
can leverage that performance potential effectively (e.g., by scaling to hundreds of cores);
\gls{hpc} users often design their computational workflows as a set of smaller,
interdependent tasks that use only a fraction of the resources of a single cluster node. Yet
executing these workflows on \gls{hpc} clusters in the presence of job managers such
as \gls{pbs} or Slurm can be challenging. They can impose limits on the concurrent
execution of multiple tasks on a single node, thus hampering node utilisation, and their design in
general is not accustomed to an enormous number of smaller, less resource-intensive tasks, which
can lead to the manager being overloaded.
