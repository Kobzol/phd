@inproceedings{wrf,
    title = {The {Weather} {Reseach} and {Forecast} {Model}: {Software} {Architecture} and {Performance}},
    author = {Michalakes, John and Dudhia, Jimy and Gill, D. and Henderson, Tom and Klemp, J. and Skamarock, W. and Wang, Wei},
    month = jan,
    year = {2004},
}
@inproceedings{cfd,
    title={CFD Vision 2030 Study: A Path to Revolutionary Computational Aerosciences},
    author={Jeffrey P. Slotnick and Abdollah Khodadoust and Juan J. Alonso and David L. Darmofal and William Gropp and Elizabeth A. Lurie and Dimitri J. Mavriplis},
    year={2014}
}
@article{hpcdl,
    author = {Ben-Nun, Tal and Hoefler, Torsten},
    title = {Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis},
    year = {2019},
    issue_date = {July 2020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {52},
    number = {4},
    issn = {0360-0300},
%    url = {https://doi.org/10.1145/3320060},
    doi = {10.1145/3320060},
%    abstract = {Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. We present trends in DNN architectures and the resulting implications on parallelization strategies. We then review and model the different types of concurrency in DNNs: from the single operator, through parallelism in network inference and training, to distributed deep learning. We discuss asynchronous stochastic optimization, distributed system architectures, communication schemes, and neural architecture search. Based on those approaches, we extrapolate potential directions for parallelism in deep learning.},
    journal = {ACM Comput. Surv.},
    month = aug,
    articleno = {65},
    numpages = {43},
%    keywords = {parallel algorithms, Deep learning, distributed computing}
}
@InProceedings{bioinformatics,
    author="Per{\'e}z-S{\'a}nchez, Horacio
and Fassihi, Afshin
and Cecilia, Jos{\'e} M.
and Ali, Hesham H.
and Cannataro, Mario",
    editor="Ortu{\~{n}}o, Francisco
and Rojas, Ignacio",
    title="Applications of High Performance Computing in Bioinformatics, Computational Biology and Computational Chemistry",
    booktitle="Bioinformatics and Biomedical Engineering",
    year="2015",
    publisher="Springer International Publishing",
    address="Cham",
    pages="527--541",
%    abstract="In the last 10 years, we are witnessing one of the major revolutions in parallel systems. The consolidation of heterogeneous systems at different levels -from desktop computers to large-scale systems such as supercomputers, clusters or grids, through all kinds of low-power devices- is providing a computational power unimaginable just few years ago, trying to follow the wake of Moore's law. This landscape in the high performance computing arena opens up great opportunities in the simulation of relevant biological systems and for applications in Bioinformatics, Computational Biology and Computational Chemistry. This introductory article shows the last tendencies of this active research field and our perspectives for the forthcoming years.",
    isbn="978-3-319-16480-9"
}
@Inbook{memorywall,
    author="McKee, Sally A.
and Wisniewski, Robert W.",
    editor="Padua, David",
    title="Memory Wall",
    bookTitle="Encyclopedia of Parallel Computing",
    year="2011",
    publisher="Springer US",
    address="Boston, MA",
    pages="1110--1116",
    isbn="978-0-387-09766-4",
    doi="10.1007/978-0-387-09766-4_234",
%    url="https://doi.org/10.1007/978-0-387-09766-4_234"
}
@Inbook{powerwall,
    author="Bose, Pradip",
    editor="Padua, David",
    title="Power Wall",
    bookTitle="Encyclopedia of Parallel Computing",
    year="2011",
    publisher="Springer US",
    address="Boston, MA",
    pages="1593--1608",
    isbn="978-0-387-09766-4",
    doi="10.1007/978-0-387-09766-4_499",
%    url="https://doi.org/10.1007/978-0-387-09766-4_499"
}
@article{xeonphi,
    title={Knights Landing: Second-Generation Intel Xeon Phi Product},
    author={Avinash Sodani and Roger Gramunt and Jes{\'u}s Corbal and Ho-Seop Kim and Krishna Vinod and Sundaram Chinthamani and Steven Hutsell and Rajat Agarwal and Yen-Chen Liu},
    journal={IEEE Micro},
    year={2016},
    volume={36},
    pages={34-46}
}
@inproceedings{mpistudy,
    author = {Laguna, Ignacio and Marshall, Ryan and Mohror, Kathryn and Ruefenacht, Martin and Skjellum, Anthony and Sultana, Nawrin},
    title = {A Large-Scale Study of MPI Usage in Open-Source HPC Applications},
    year = {2019},
    isbn = {9781450362290},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3295500.3356176},
    booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
    articleno = {31},
    numpages = {14},
    location = {Denver, Colorado},
    series = {SC '19}
}
@inproceedings{dace,
    author = {Ben-Nun, Tal and de Fine Licht, Johannes and Ziogas, Alexandros N. and Schneider, Timo and Hoefler, Torsten},
    title = {Stateful Dataflow Multigraphs: A Data-Centric Model for Performance Portability on Heterogeneous Architectures},
    year = {2019},
    isbn = {9781450362290},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
%    url = {https://doi.org/10.1145/3295500.3356173},
    doi = {10.1145/3295500.3356173},
%    abstract = {The ubiquity of accelerators in high-performance computing has driven programming complexity beyond the skill-set of the average domain scientist. To maintain performance portability in the future, it is imperative to decouple architecture-specific programming paradigms from the underlying scientific computations. We present the Stateful DataFlow multiGraph (SDFG), a data-centric intermediate representation that enables separating program definition from its optimization. By combining fine-grained data dependencies with high-level control-flow, SDFGs are both expressive and amenable to program transformations, such as tiling and double-buffering. These transformations are applied to the SDFG in an interactive process, using extensible pattern matching, graph rewriting, and a graphical user interface. We demonstrate SDFGs on CPUs, GPUs, and FPGAs over various motifs --- from fundamental computational kernels to graph analytics. We show that SDFGs deliver competitive performance, allowing domain scientists to develop applications naturally and port them to approach peak hardware performance without modifying the original scientific code.},
    booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
    articleno = {81},
    numpages = {14},
    location = {Denver, Colorado},
    series = {SC '19}
}
@Article{starpu,
    author = {C{\'e}dric Augonnet and Samuel Thibault and Raymond Namyst and Pierre-Andr{\'e} Wacrenier},
    title = {{StarPU: A Unified Platform for Task Scheduling on Heterogeneous Multicore Architectures}},
    journal = {CCPE - Concurrency and Computation: Practice and Experience, Special Issue: Euro-Par 2009},
    volume = 23,
    issue = 2,
    pages = {187--198},
    year = 2011,
    month = FEB,
    publisher = {John Wiley & Sons, Ltd.},
    doi = {10.1002/cpe.1631},
    url = {http://hal.inria.fr/inria-00550877},
    pdf = {http://hal.inria.fr/inria-00550877/document},
    KEYWORDS = {General Presentations;StarPU}
}
@book{openmp,
    title={Parallel programming in OpenMP},
    author={Chandra, Rohit and Dagum, Leo and Kohr, David and Menon, Ramesh and Maydan, Dror and McDonald, Jeff},
    year={2001},
    publisher={Morgan kaufmann}
}
@ARTICLE{mooreslaw,
    author={Schaller, R.R.},
    journal={IEEE Spectrum},
    title={Moore's law: past, present and future},
    year={1997},
    volume={34},
    number={6},
    pages={52-59},
    doi={10.1109/6.591665}
}
@online{top500gpu,
    author={Feldman, Michael},
    url={https://www.top500.org/news/new-gpu-accelerated-supercomputers-change-the-balance-of-power-on-the-top500/},
    urldate = {2023-04-21},
}

% Technologies
@techreport{mpi,
    author = {Forum, Message P},
    title = {MPI: A Message-Passing Interface Standard},
    year = {1994},
    publisher = {University of Tennessee},
    address = {USA},
%    abstract = {The Message Passing Interface Forum (MPIF), with participation from over 40 organizations, has been meeting since November 1992 to discuss and define a set of library standards for message passing. MPIF is not sanctioned or supported by any official standards organization. The goal of the Message Passing Interface, simply stated, is to develop a widely used standard for writing message-passing programs. As such the interface should establish a practical, portable, efficient and flexible standard for message passing. , This is the final report, Version 1.0, of the Message Passing Interface Forum. This document contains all the technical features proposed for the interface. This copy of the draft was processed by LATEX on April 21, 1994. , Please send comments on MPI to mpi-comments@cs.utk.edu. Your comment will be forwarded to MPIF committee members who will attempt to respond.}
}
@Inbook{pgas,
    author="Almasi, George",
    editor="Padua, David",
    title="PGAS (Partitioned Global Address Space) Languages",
    bookTitle="Encyclopedia of Parallel Computing",
    year="2011",
    publisher="Springer US",
    address="Boston, MA",
    pages="1539--1545",
    isbn="978-0-387-09766-4",
    doi="10.1007/978-0-387-09766-4_210",
%    url="https://doi.org/10.1007/978-0-387-09766-4_210"
}

% Distributed tools
@inproceedings{dask,
    author = {Rocklin, Matthew},
    year = {2015},
    month = {01},
    pages = {126-132},
    title = {Dask: Parallel Computation with Blocked algorithms and Task Scheduling},
    doi = {10.25080/Majora-7b98e3ed-013}
}
@article{snakemake,
    author = {Köster, Johannes and Rahmann, Sven},
    title = "{Snakemake—a scalable bioinformatics workflow engine}",
    journal = {Bioinformatics},
    volume = {28},
    number = {19},
    pages = {2520-2522},
    year = {2012},
    month = {08},
    abstract = "{Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames.Availability:http://snakemake.googlecode.com.Contact:johannes.koester@uni-due.de}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bts480},
    %    url = "https://doi.org/10.1093/bioinformatics/bts480",
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/28/19/2520/819790/bts480.pdf},
}
@article{nextflow,
    author = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W. and Barja, Pablo and Palumbo, Emilio and Notredame, Cedric},
    year = {2017},
    month = {04},
    pages = {316-319},
    title = {Nextflow enables reproducible computational workflows},
    volume = {35},
    journal = {Nature Biotechnology},
    doi = {10.1038/nbt.3820}
}
@article{aiida,
    author="Huber, Sebastiaan P.
and Zoupanos, Spyros
and Uhrin, Martin
and Talirz, Leopold
and Kahle, Leonid
and H{\"a}uselmann, Rico
and Gresch, Dominik
and M{\"u}ller, Tiziano
and Yakutovich, Aliaksandr V.
and Andersen, Casper W.
and Ramirez, Francisco F.
and Adorf, Carl S.
and Gargiulo, Fernando
and Kumbhar, Snehal
and Passaro, Elsa
and Johnston, Conrad
and Merkys, Andrius
and Cepellotti, Andrea
and Mounet, Nicolas
and Marzari, Nicola
and Kozinsky, Boris
and Pizzi, Giovanni",
    title="AiiDA 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance",
    journal="Scientific Data",
    year="2020",
    month="Sep",
    day="08",
    volume="7",
    number="1",
    pages="300",
    abstract="The ever-growing availability of computing power and the sustained development of advanced computational methods have contributed much to recent scientific progress. These developments present new challenges driven by the sheer amount of calculations and data to manage. Next-generation exascale supercomputers will harden these challenges, such that automated and scalable solutions become crucial. In recent years, we have been developing AiiDA (aiida.net), a robust open-source high-throughput infrastructure addressing the challenges arising from the needs of automated workflow management and data provenance recording. Here, we introduce developments and capabilities required to reach sustained performance, with AiiDA supporting throughputs of tens of thousands processes/hour, while automatically preserving and storing the full data provenance in a relational database making it queryable and traversable, thus enabling high-performance data analytics. AiiDA's workflow language provides advanced automation, error handling features and a flexible plugin model to allow interfacing with external simulation software. The associated plugin registry enables seamless sharing of extensions, empowering a vibrant user community dedicated to making simulations more robust, user-friendly and reproducible.",
    issn="2052-4463",
    doi="10.1038/s41597-020-00638-4",
%    url="https://doi.org/10.1038/s41597-020-00638-4"
}
@article{streamflow,
    abstract = {Workflows are among the most commonly used tools in a variety of execution environments. Many of them target a specific environment; few of them make it possible to execute an entire workflow in different environments, e.g. Kubernetes and batch clusters. We present a novel approach to workflow execution, called StreamFlow, that complements the workflow graph with the declarative description of potentially complex execution environments, and that makes it possible the execution onto multiple sites not sharing a common data space. StreamFlow is then exemplified on a novel bioinformatics pipeline for single cell transcriptomic data analysis workflow.},
    author = {Iacopo Colonnelli and Barbara Cantalupo and Ivan Merelli and Marco Aldinucci},
    doi = {10.1109/TETC.2020.3019202},
    journal = {{IEEE} {T}ransactions on {E}merging {T}opics in {C}omputing},
    number = {4},
    pages = {1723--1737},
    title = {{StreamFlow}: cross-breeding cloud with {HPC}},
    volume = {9},
    year = {2021}
}
